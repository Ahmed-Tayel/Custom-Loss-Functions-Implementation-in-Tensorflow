{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "On_Loss__Functions_Classification_V2",
      "provenance": [],
      "collapsed_sections": [
        "R6DMvR8TzJiK",
        "egL15iQztTDH",
        "k6bNy-J9u-l6"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDEJU1RwoIlv"
      },
      "source": [
        "##Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSKuPnIXNoq2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60eb8bef-ec1c-424b-f297-e70c6cf74b8b"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "print(\"Tensorflow version \", tf.__version__)\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  print('GPU device not found')\n",
        "print('Found GPU at: ', device_name)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensorflow version  2.6.0\n",
            "Found GPU at:  /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KaeLRpWIfO1m"
      },
      "source": [
        "## Load data\n",
        "\n",
        "Load training data from Keras library\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpt_UTZEi5Uv"
      },
      "source": [
        "### MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kECuF5cgxxW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65915ac9-c06e-400b-ade0-fcec7c376175"
      },
      "source": [
        "def load_data_MNIST():\n",
        "    # load data\n",
        "    (Xtrain,Ytrain), (Xtest, Ytest) = mnist.load_data()\n",
        "\n",
        "    # get information\n",
        "    ninput = Xtrain.shape[0]\n",
        "    imgsize = (Xtrain.shape[1], Xtrain.shape[2])\n",
        "    input_shape = (Xtrain.shape[1], Xtrain.shape[2], 1)\n",
        "    ntest = Xtest.shape[0]\n",
        "    num_classes = max(Ytrain) + 1\n",
        "    print(\"Training input: \" , Xtrain.shape)\n",
        "    print(\"Training output: \" , Ytrain.shape)\n",
        "    print(\"Test input: \"  , Xtest.shape)\n",
        "    print(\"Test output: \" , Ytest.shape)\n",
        "    print(\"Input shape: \" , input_shape)\n",
        "    print(\"Number of classes: \" , num_classes)\n",
        "\n",
        "    # normalize input to [0,1]\n",
        "    Xtrain = Xtrain / 255.0\n",
        "    Xtest = Xtest / 255.0\n",
        "    # reshape input in 4D array\n",
        "    Xtrain = Xtrain.reshape(ninput,imgsize[0],imgsize[1],1)\n",
        "    Xtest = Xtest.reshape(ntest,imgsize[0],imgsize[1],1)\n",
        "    \n",
        "    # Transform output to one hot encoding\n",
        "    Ytrain = to_categorical(Ytrain, num_classes)\n",
        "    Ytest = to_categorical(Ytest, num_classes)\n",
        "    \n",
        "    return [Xtrain,Ytrain,Xtest,Ytest,input_shape,num_classes]\n",
        "\n",
        "[Xtrain_mnist,Ytrain_mnist,Xtest_mnist,Ytest_mnist,input_shape_mnist,num_classes_mnist] = load_data_MNIST()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training input:  (60000, 28, 28)\n",
            "Training output:  (60000,)\n",
            "Test input:  (10000, 28, 28)\n",
            "Test output:  (10000,)\n",
            "Input shape:  (28, 28, 1)\n",
            "Number of classes:  10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5OnoMmKmfMEY"
      },
      "source": [
        "#### Show random image\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "NsTOUlIlfMEY",
        "outputId": "48f66b18-7f92-46ad-942d-455daf33b1ad"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "i = random.randrange(0,Xtrain_mnist.shape[0])\n",
        "image = Xtrain_mnist[i]\n",
        "image = np.array(image, dtype='float')\n",
        "pixels = image.reshape((28, 28))\n",
        "\n",
        "label = Ytrain_mnist[i].argmax()  # categorical from one-hot-encoding\n",
        "print(label)\n",
        "\n",
        "plt.imshow(pixels, cmap='gray')\n",
        "plt.show()\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bV3gt6OHdlcX"
      },
      "source": [
        "### CIFAR 10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dUe0X_rTc-Z",
        "outputId": "d4e318af-498e-486d-b284-7ffc4496faf5"
      },
      "source": [
        "def load_data_CIFAR10():\n",
        "    # load data\n",
        "    (Xtrain,Ytrain), (Xtest, Ytest) = keras.datasets.cifar10.load_data()\n",
        "\n",
        "    # get information\n",
        "    ninput = Xtrain.shape[0]\n",
        "    imgsize = (Xtrain.shape[1], Xtrain.shape[2])\n",
        "    input_shape = (Xtrain.shape[1], Xtrain.shape[2], Xtrain.shape[3])\n",
        "    ntest = Xtest.shape[0]\n",
        "    num_classes = 10\n",
        "    print(\"Training input: \" , Xtrain.shape)\n",
        "    print(\"Training output: \" , Ytrain.shape)\n",
        "    print(\"Test input: \"  , Xtest.shape)\n",
        "    print(\"Test output: \" , Ytest.shape)\n",
        "    print(\"Input shape: \" , input_shape)\n",
        "    print(\"Number of classes: \" , num_classes)\n",
        "\n",
        "    # normalize input to [0,1]\n",
        "    Xtrain = Xtrain / 255.0\n",
        "    Xtest = Xtest / 255.0\n",
        "    # reshape input in 4D array\n",
        "    Xtrain = Xtrain.reshape(ninput,imgsize[0],imgsize[1],3)\n",
        "    Xtest = Xtest.reshape(ntest,imgsize[0],imgsize[1],3)\n",
        "    \n",
        "    # Transform output to one-out-of-n encoding\n",
        "    Ytrain = to_categorical(Ytrain.tolist()[:], num_classes)\n",
        "    Ytest = to_categorical(Ytest.tolist()[:], num_classes)\n",
        "    \n",
        "    return [Xtrain,Ytrain,Xtest,Ytest,input_shape,num_classes]\n",
        "\n",
        "[Xtrain_cifar10,Ytrain_cifar10,Xtest_cifar10,Ytest_cifar10,input_shape_cifar10,num_classes_cifar10] = load_data_CIFAR10()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training input:  (50000, 32, 32, 3)\n",
            "Training output:  (50000, 1)\n",
            "Test input:  (10000, 32, 32, 3)\n",
            "Test output:  (10000, 1)\n",
            "Input shape:  (32, 32, 3)\n",
            "Number of classes:  10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6DMvR8TzJiK"
      },
      "source": [
        "#### Show random image\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0N3cUSazRcJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "306a2df3-b8e5-4b90-c771-9f16a16d3424"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "i = random.randrange(0,Xtrain_cifar10.shape[0])\n",
        "image = Xtrain_cifar10[i]\n",
        "image = np.array(image, dtype='float')\n",
        "pixels = image.reshape((32, 32, 3))\n",
        "\n",
        "label = Ytrain_cifar10[i].argmax()  # categorical from one-hot-encoding\n",
        "print(label)\n",
        "\n",
        "plt.imshow(image)\n",
        "plt.show()\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAZlklEQVR4nO2dbYxcZ3XH/2de1vvqtR0bx3EiHNJIVYRKQCsrLQhREChFSAGpiqBSlA8RRhWRikQ/RKlUUqkfoCogPlRUpokIiBJSXkRURS1phBSB1JANTZyElBIiB2L8GjvrXe/sztvph7mu1uk9/9m9M3PH8fP/SaudvWeee8995p69M89/zjnm7hBCXPlUxu2AEKIcFOxCJIKCXYhEULALkQgKdiESQcEuRCLUBhlsZrcC+AqAKoB/cvfPs+dPTU379vn5/H3RA23ZcEVjxSaLjIjlV+MHu+wJz4wozlyMLiZVD1/hzt/h0tISGquruS9a4WA3syqAfwDwQQCvAnjKzB5x919EY7bPz+PP7rgz11apxG8yogvO6RuT+CItfgF3g/0RLwoei42rkrli8xiO8U5oq1W3/rrQYxXwr9+xuiSS2vkvGTrdeAz77km3G+ywjx9sn5GNfgcmsH3z6/eHQwZ5G38QwEvu/rK7NwE8BOC2AfYnhBghgwT7fgC/3fD3q9k2IcRlyMgX6MzskJktmtliY3V11IcTQgQMEuzHAFy34e9rs22X4O6H3X3B3RempqcHOJwQYhAGCfanANxoZteb2QSAjwN4ZDhuCSGGTeHVeHdvm9ndAP4dPentAXd/oc+oYiuPEQUX1dmx2AJzPI75PvzVZ76yG+2P+RjbOp14pb6QglJQg+Ir5Gw+tu4HW3EvvFJPbNFcUT+Cc2bTO5DO7u6PAnh0kH0IIcpB36ATIhEU7EIkgoJdiERQsAuRCAp2IRJhoNX4soikCaNJFcNPQIn3WSxrjNkqRcdVgrki8xEMycbF51aq9EZkKJbU0g3uZyxppWyKyNHu8XxE6M4uRCIo2IVIBAW7EImgYBciERTsQiTCm2I1PloFL7ZyXmw1G2BJBsNfjS9aOCtc2SVj2Gp8kWONAqa8VIJyYQAQLtQXdH0U5xwlvBRLyCHqyVacEkK8eVGwC5EICnYhEkHBLkQiKNiFSAQFuxCJULr0FkkGTGYI90VsLJEERMbxLpHDAt+LS2jkDAp2konml+6taE0+Jg1F+6OnzGTKeFyFymGBjSSScEGXJKcwmxF5EPl1/rqkU0+RflK6swuRCAp2IRJBwS5EIijYhUgEBbsQiaBgFyIRBpLezOwogGUAHQBtd19gz3cHOoFcU2VyWCQzdGNpwll9tK33uM/G5YsyLFOOS17EVvTfcFSvjx2KTEiVtaEqUEOvQhRWmlFG2y7Fw6pRRhyr4UaVvHhchdjYucXjti5HM+eHobP/sbufGcJ+hBAjRG/jhUiEQYPdAfzIzJ42s0PDcEgIMRoGfRv/Hnc/ZmZvAfCYmf23uz+x8QnZP4FDADA7Nzfg4YQQRRnozu7ux7LfpwD8AMDBnOccdvcFd1+Ympoe5HBCiAEoHOxmNmNmcxcfA/gQgOeH5ZgQYrgM8jZ+L4AfZJlKNQD/7O7/Rke4o9Nu59uq1S07wAtOFoNmXoUZewX3R/yoIZ4PetaBkWUBVmrxZbDeXAttzWYrtLXb+bYKkzZjE201NVGfILZ6/naL99fpbD2bDwBq5Ay6RJaLimJ2iFzXDg7F2nwVDnZ3fxnAO4qOF0KUi6Q3IRJBwS5EIijYhUgEBbsQiaBgFyIRSi046XB0OqSI3hZhshbLMqIZSFQqy7exQoO8r1z8v7ZL5okWRAyO12g2wzFHj70S2n7z6m9C2/mlpdC2HhzP2/F5sfmoBxIaAMzNzoa2q+bmc7fvv2Z/OOaa/deENiZtVVnhziBjktrImG6BZnW6swuRCAp2IRJBwS5EIijYhUgEBbsQiVDuaryj0Gp82NKo4Eo3HUds3WgltmBLI+Zjs2CST7Wav0+2qv7T//xpaFttrIa2JlnhD9t5kSQTNh/MxtSVWpDwsmPHjnDMwYP/L1P7/zhw4EBoq0QZLQCc2LphglUcK52wrRVRmkKLEOKKQsEuRCIo2IVIBAW7EImgYBciERTsQiRCqdIbSCIMk0+qQX06JpNRCYLUH+vSVk5BayUivbEGPqwuGYgfLAWi7fnntk4K5U1OzYS2C6ux9MZScubn8xNQrtq1KxzTXI+lvJWVldC2fW57aJueyT+3s+fOhWOefSGum7rjqtj/OVI9mUnOkSwXype9UflbJb0JIRTsQiSCgl2IRFCwC5EICnYhEkHBLkQi9JXezOwBAB8BcMrd355t2wXgOwAOADgK4HZ3j7WMDPd+ckLoQ+52JqEZTUVjWhnJTiqQiUZbVLG2UUyWY62LgvNuBV23AKBa2RbaapW4tVLHYjlpbjZf8rr2mmvDMasXYpnvRPdEaHvrWw+Etj1782vN/fY3cd2918+eDm3dVtzyyusko5Nk+0VXiLFrMYojcmlv5s7+dQC3vmHbPQAed/cbATye/S2EuIzpG+xZv/Wzb9h8G4AHs8cPAvjokP0SQgyZop/Z97r78ezxCfQ6ugohLmMGXqDz3vfzwk8KZnbIzBbNbHF9LW7/K4QYLUWD/aSZ7QOA7Pep6InuftjdF9x9YdvkZMHDCSEGpWiwPwLgzuzxnQB+OBx3hBCjYjPS27cBvA/AbjN7FcDnAHwewMNmdheAVwDcvrnDeSgZMIkqGuOs/ROV3mIZhGWUURktoGihRKKuUdrBPi801uNBlfgymJ6NM8qwSubD8jMV2f1lcjLOvts2GWeUtVqx5NUIPjo2m7GEVqvF8+FEOu60Y32TFZyMKCJTM/oGu7t/IjB9YKieCCFGir5BJ0QiKNiFSAQFuxCJoGAXIhEU7EIkQskFJ2O5qYjMwLLQmEhWREIbZFwR3ONjdUi63Nml5dztLZJ1NUEKJba7sZxUacdy3mozf9zps6+HY1jByXPBefUciS/jSj3/i1xOsgobjUZoW1m5ENqm6nH2YJfMfzimQEyo4KQQQsEuRCoo2IVIBAW7EImgYBciERTsQiRCqdIbKzjJJIOob1uHKWEso2zI0hvbH81sI+Oq26ZCW6tNsvaCbLO5+bhHWb1eD21X7dlNxsX+Nxr5ElW3Gc9HuxPLWtt3xn5Y0AsQiK+3q6++OhxzYTmWB5eXYwlwz854jodNLMtJehMieRTsQiSCgl2IRFCwC5EICnYhEqHkRBhHp5NfL6zIijZdVGer+wVX4yvhOLKqXo3/n9Yn4tZKTorQbZuKq/TOV/JX1mdIYk3N4rL/lQprQxXb2q38pJZum7Q06hRodwSgTmrGTU/mz3HF4wSfTitO8FlbjVfjm804kYddj5Gpy67hUNWKh+jOLkQiKNiFSAQFuxCJoGAXIhEU7EIkgoJdiETYTPunBwB8BMApd397tu0+AJ8EcDp72r3u/mi/fXU6juXVfFnDSJukWpDoUCeyUJXsz1iFOmKKWjmx/VWY9EbksOO/+x3xI37Z3rI7X0abn5uP91eN9ZpOJ26T1CZ11SrBa2Y1MsEsFyo20XqD1WCqKmF7KuDa6w+EtlMnj4e29WZcuy66hgGgg3xbl7SMqnTzJWzW9mwzd/avA7g1Z/uX3f3m7KdvoAshxkvfYHf3JwCcLcEXIcQIGeQz+91mdsTMHjCznUPzSAgxEooG+1cB3ADgZgDHAXwxeqKZHTKzRTNbbDZJ22AhxEgpFOzuftLdO96rtP81AAfJcw+7+4K7L0xMxEX0hRCjpVCwm9m+DX9+DMDzw3FHCDEqNiO9fRvA+wDsNrNXAXwOwPvM7Gb0FJGjAD61mYN1vYuVxlqujUll1UC2qBLpikpvJdagi7L8AOC1s6+FtlNniPRG3N99yx/lbq9Nxy91tx3LazVybpO1WE6qTATSG8nmi6RNADBy0kzWguVLUexYTOib2RaPO/m7E6Ft6XxcX68TyICdLskEDTLz2u34eusb7O7+iZzN9/cbJ4S4vNA36IRIBAW7EImgYBciERTsQiSCgl2IRCi14GSlUsX2ubnAtvUstQprrURyoZhUVqzwZTyGFUqMC1jG0goANFtxdtXLvzySu/3M7HQ4hiTm0dqckSTaG7d1ebNGCkeyFlVsjqem8ttoTU7GRTvr9diPycl4HmuTccuuMyfi9JL1oNBml0jL3Wa+XNpimYihRQhxRaFgFyIRFOxCJIKCXYhEULALkQgKdiESoWTpzTAR9DdjMk4ky7GsN2eS15Az4orur9XaE9rOnTsZ2tZIn7J2N7/fWMfJS03kGjobXuA1IzofkyKb63EftaWlpdB29dXX5G4/e2ElHDM5GdddWJvMz9oEgEYzno/Z7bOhbSKS3si9OOqLVyHype7sQiSCgl2IRFCwC5EICnYhEkHBLkQilLoa7+5ot+OV5HjgFreDryKzxIkiSTJRgkw/2/RMnFQxM39VaLuwFifCvLacv8o8vT1O0mDtpNgcs1eyErwCTu4vRtSVSi1fxQGAXXvyW14BQKWen/BSJZd+lVRBrk7E84j11dBUs3i26tvyz61D5qrdzr+GWX1C3dmFSAQFuxCJoGAXIhEU7EIkgoJdiERQsAuRCJtp/3QdgG8A2IueEHPY3b9iZrsAfAfAAfRaQN3u7uf67S+Sopgk1w5EnnqVyCesvQ+Rw7pdojUV2B+rq2Yk+WeGJE746Xjc0vL5fD9Oxok1c6Su2tS2WGqamIjrwkU2I/cXMo1gYmqlEs9H1H6L1Zlj0izrRFyrxfNRacb7jPKQ2sSPTjCIzeFm7uxtAJ9195sA3ALg02Z2E4B7ADzu7jcCeDz7WwhxmdI32N39uLv/PHu8DOBFAPsB3AbgwexpDwL46KicFEIMzpY+s5vZAQDvBPAkgL3ufjwznUDvbb4Q4jJl08FuZrMAvgfgM+5+yQdD730Qz/20YGaHzGzRzBab63HivxBitGwq2M2sjl6gf8vdv59tPmlm+zL7PgCn8sa6+2F3X3D3hYltcWF+IcRo6Rvs1sv+uB/Ai+7+pQ2mRwDcmT2+E8APh++eEGJYbCbr7d0A7gDwnJk9k227F8DnATxsZncBeAXA7f125B7LGkXaLrHab+12vuTS71jM1unm79OM1QqL/QBiaWVyMs7ymiAZYFNzO3K3z83GstD6yoXQtvx6vpQH8LqBUdulman43d3MFJEAp0m2GasBWAnmP6jhBgAk+Q5t8nq2LT63DqnXt9bK32ebZQGSay6ib7C7+08Qi5wf2PIRhRBjQd+gEyIRFOxCJIKCXYhEULALkQgKdiESoeSCk12sr+dnDRWR3limHMtcoploxI+1tfxvALIx27bFxQtZVcwqyejbsTMuRtlYzk88nJ6OZa356ZnQ1glkIQBYXl4ObSsr+YUvl8/HY9g5s5ZMU+TcpgMJsB60IQO4pBtlmwFA20nWW1D4EgA63fwLoUOkt8gLd9L2LLQIIa4oFOxCJIKCXYhEULALkQgKdiESQcEuRCKUKr11Op1QrmFSWSSFTBD5hMHkMCajtVqt3O3M90K97QC4xVlZc3Pz8bhWvrR5YSUuHDI9EWdkTZK+Zzt37gxtE8G4lQtxn7r1Zv78AsBKoxnaGs14jldW88+b9eBj0lujEc/janAsAJjfsTu0ze7Ylbt9jcxHJGG3g2sU0J1diGRQsAuRCAp2IRJBwS5EIijYhUiEUlfju11HI0gmcbKiHa2esxVV7kexJJkomYT5EbUf6m8LTahVYh/nZvNX6pfP5yemAEDT44NVSLZOp0NadgUqRJfsr0sSP9bW49X4ajW+Z+15y77c7a1WvL9ISQCAdudMaGucfi20dUhNxFYwVxfWYh+jVXem/ujOLkQiKNiFSAQFuxCJoGAXIhEU7EIkgoJdiEToK72Z2XUAvoFeS2YHcNjdv2Jm9wH4JIDT2VPvdfdH6cFqVezYkS8NdUltr6BBLE1aYa2JGEwOiyS2qDYdANSJlFdhPpL6dJF8CQDdZn6CRLMZy4NGzrlCZL5WK5Z5Go18P5ZJssjaWv4YgEtKLLFpPZCoVlfjhJwJci222rHNSAINk/pWlvNbbDGZ0oJr0YJYATans7cBfNbdf25mcwCeNrPHMtuX3f3vN7EPIcSY2Uyvt+MAjmePl83sRQD7R+2YEGK4bOkzu5kdAPBOAE9mm+42syNm9oCZxcnNQoixs+lgN7NZAN8D8Bl3Pw/gqwBuAHAzenf+LwbjDpnZopkttprx5xYhxGjZVLCbWR29QP+Wu38fANz9pLt3vFeV/msADuaNdffD7r7g7gusML8QYrT0DXbrLXnfD+BFd//Shu0bMww+BuD54bsnhBgWm1mNfzeAOwA8Z2bPZNvuBfAJM7sZPV3sKIBP9dtRu9XCmdOntuxkJK1s374jHMOy11jWG8tgi2y0Bh2RtapEWml3iB+V2NYIpLcO4ndVa01SV60RZ8utrq6Gtkj6ZBlqraB+Xj/q9VjCjOratcj8NkiGYMVi/+uTcRuqBpH66gVktHY7f65Y+6fNrMb/BPmqL9XUhRCXF/oGnRCJoGAXIhEU7EIkgoJdiERQsAuRCKUWnHT3sIUSy1yKMtFYthnLiGPtfYq0cqrX6wWPFUsr9Xr80hhiqakzke+LB1INAFxYJhlgxI/JyanQFklsTF6bnJwMbTWSIVipEFswjkmzTfJNzwqVdIsVHo0kXVqQtJtvYyVYdWcXIhEU7EIkgoJdiERQsAuRCAp2IRJBwS5EIpQqvVmlEkpsEyTXfX09KF4YFOoDuHzCZD4mlUWwTDm2PyatGOmjVquQ/muBtLW6vBSOWV+LpTfzeK5A5M3l5XxZtEIy9qamY+mtS+aqSzK92kFRTPaaMVmOyb2sOAt7raPrmxZUreVLiqROqe7sQqSCgl2IRFCwC5EICnYhEkHBLkQiKNiFSIRypTezUGJjmWNx1lssdTQasZzEZJeZmZnQFhVRZEUlGUziWV+PJZ7lleXQdv7cmdztLSKvsUw/1leO+R/ZquSKo4VA42GUZlCAs+skK5Jk2DF5rUX60RUpcsqKc8bqKzmv0CKEuKJQsAuRCAp2IRJBwS5EIijYhUiEvqvxZjYJ4AkA27Lnf9fdP2dm1wN4CMBVAJ4GcIe70zat3W43bBkUrXQD8Wo8q4HGEmvYSn2DtDSyaAmULBWzlX+22nqBJPmce+10aLNu/opwrcZSJGIlxEi7I7YaXwmXi+NVaVg8V2w1u9OJbUtL+fNYr8fXx8xM3MapFSTWAEA3qAvXO97WlQuaCBNcO2TIpu7s6wDe7+7vQK89861mdguALwD4srv/HoBzAO7axL6EEGOib7B7j4ud7urZjwN4P4DvZtsfBPDRkXgohBgKm+3PXs06uJ4C8BiAXwN43d0vvqd5FcD+0bgohBgGmwp2d++4+80ArgVwEMDvb/YAZnbIzBbNbLFDvmEkhBgtW1qNd/fXAfwYwB8C2GFmF1cWrgVwLBhz2N0X3H2hShZ0hBCjpW+wm9keM9uRPZ4C8EEAL6IX9H+aPe1OAD8clZNCiMHZzK12H4AHzayK3j+Hh939X83sFwAeMrO/BfBfAO7vuyd3oJ0vTzRIgoEFddxqtfhjgXss5TGJpNlkdeHyW1c1SZIJk4U6pM5cq0VUTDIukniYjMMlHtZ2Kb5XRJIjb5FEkkWIYtdux8ZmIJXVWK1B1paLzMc6kQ6dnYDlX3NVkjXUaOQnKLH57Rvs7n4EwDtztr+M3ud3IcSbAH2DTohEULALkQgKdiESQcEuRCIo2IVIBGNZWUM/mNlpAK9kf+4GkF8wrVzkx6XIj0t5s/nxVnffk2coNdgvObDZorsvjOXg8kN+JOiH3sYLkQgKdiESYZzBfniMx96I/LgU+XEpV4wfY/vMLoQoF72NFyIRxhLsZnarmf3SzF4ys3vG4UPmx1Eze87MnjGzxRKP+4CZnTKz5zds22Vmj5nZr7LfO8fkx31mdiybk2fM7MMl+HGdmf3YzH5hZi+Y2V9k20udE+JHqXNiZpNm9jMzezbz42+y7deb2ZNZ3HzHzOKqmXm4e6k/AKrolbV6G4AJAM8CuKlsPzJfjgLYPYbjvhfAuwA8v2Hb3wG4J3t8D4AvjMmP+wD8ZcnzsQ/Au7LHcwD+B8BNZc8J8aPUOUGvYdts9rgO4EkAtwB4GMDHs+3/CODPt7LfcdzZDwJ4yd1f9l7p6YcA3DYGP8aGuz8B4OwbNt+GXuFOoKQCnoEfpePux93959njZfSKo+xHyXNC/CgV7zH0Iq/jCPb9AH674e9xFqt0AD8ys6fN7NCYfLjIXnc/nj0+AWDvGH2528yOZG/zR/5xYiNmdgC9+glPYoxz8gY/gJLnZBRFXlNfoHuPu78LwJ8A+LSZvXfcDgG9/+wo3qV4UL4K4Ab0egQcB/DFsg5sZrMAvgfgM+5+SXeHMuckx4/S58QHKPIaMY5gPwbgug1/h8UqR427H8t+nwLwA4y38s5JM9sHANnvU+Nwwt1PZhdaF8DXUNKcmFkdvQD7lrt/P9tc+pzk+TGuOcmOveUirxHjCPanANyYrSxOAPg4gEfKdsLMZsxs7uJjAB8C8DwfNVIeQa9wJzDGAp4XgyvjYyhhTqxXBO9+AC+6+5c2mEqdk8iPsudkZEVey1phfMNq44fRW+n8NYC/GpMPb0NPCXgWwAtl+gHg2+i9HWyh99nrLvR65j0O4FcA/gPArjH58U0AzwE4gl6w7SvBj/eg9xb9CIBnsp8Plz0nxI9S5wTAH6BXxPUIev9Y/nrDNfszAC8B+BcA27ayX32DTohESH2BTohkULALkQgKdiESQcEuRCIo2IVIBAW7EImgYBciERTsQiTC/wIpS7lAoQW/twAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMqTLBFjBuqZ"
      },
      "source": [
        "## Custom Softmax Loss Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q87h8pkTHQhs"
      },
      "source": [
        "### 1) L1 Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-G9MTs1R_go"
      },
      "source": [
        "@tf.function\n",
        "def l1_loss(y_true, y_pred):\n",
        "  L1_loss_calc = tf.reduce_sum(tf.abs(tf.subtract(y_true, y_pred)) ,axis = 1, keepdims=True)\n",
        "  return tf.divide(tf.reduce_sum(L1_loss_calc),L1_loss_calc.shape[0])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qf4rBcnHQ6c"
      },
      "source": [
        "### 2) L2 Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZxx1dZBULna"
      },
      "source": [
        "@tf.function\n",
        "def l2_loss(y_true, y_pred):\n",
        "  L2_loss = tf.norm(tf.subtract(y_true, y_pred), axis= 1) ** 2\n",
        "  return tf.divide(tf.reduce_sum(L2_loss),L2_loss.shape[0])"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4p5q_wqHRLE"
      },
      "source": [
        "### 3) Expectation Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWpp7VHaWDIa"
      },
      "source": [
        "@tf.function\n",
        "def expectation_loss(y_true, y_pred):\n",
        "  # Apply Softmax\n",
        "  y_pred_sum = tf.reduce_sum(y_pred,axis = 1, keepdims=True)\n",
        "  y_pred_ratio = tf.divide(y_pred,y_pred_sum)\n",
        "  # Apply L1 loss\n",
        "  L1_loss = tf.reduce_sum(tf.abs(tf.subtract(y_true, y_pred_ratio)) ,axis = 1, keepdims=True)\n",
        "  return tf.divide(tf.reduce_sum(L1_loss),L1_loss.shape[0])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4D6xaj5HRb0"
      },
      "source": [
        "### 4) Regularised Expectation Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E187yvJpWglu"
      },
      "source": [
        "@tf.function\n",
        "def regularized_expectation_loss(y_true, y_pred):\n",
        "  # Apply Softmax\n",
        "  y_pred_sum = tf.reduce_sum(y_pred,axis = 1, keepdims=True)\n",
        "  y_pred_ratio = tf.divide(y_pred,y_pred_sum)\n",
        "  # Apply L2 loss\n",
        "  L2_loss = tf.norm(tf.subtract(y_true, y_pred_ratio), axis= 1) ** 2\n",
        "  return tf.divide(tf.reduce_sum(L2_loss),L2_loss.shape[0])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mx-DvcoVHRqM"
      },
      "source": [
        "### 5) Chebyshev loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfC8XCUWXmzH"
      },
      "source": [
        "@tf.function\n",
        "def chebyshev_loss(y_true, y_pred):\n",
        "  # Apply Softmax\n",
        "  y_pred_sum = tf.reduce_sum(y_pred,axis = 1, keepdims=True)\n",
        "  y_pred_ratio = tf.divide(y_pred,y_pred_sum)\n",
        "  # Apply cheb loss\n",
        "  cheb_loss = tf.reduce_max(tf.abs(tf.subtract(y_true, y_pred_ratio)) ,axis = 1, keepdims=True)\n",
        "  return tf.divide(tf.reduce_sum(cheb_loss),cheb_loss.shape[0])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COu8alqmHR40"
      },
      "source": [
        "### 6) hinge (margin) loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Zu9UZlha3kw"
      },
      "source": [
        "@tf.function\n",
        "def hinge_loss(y_true, y_pred):\n",
        "  y_product = tf.math.multiply(y_true,y_pred)\n",
        "  max_second_arg = tf.constant(0.5) - y_product\n",
        "  max_compare = tf.math.maximum(tf.constant(0.0), max_second_arg)\n",
        "\n",
        "  y_product_red = tf.reduce_sum(max_compare,axis = 1, keepdims=True)\n",
        "  y_product_red_abs = tf.abs(y_product_red)\n",
        "\n",
        "  return tf.divide(tf.reduce_sum(y_product_red_abs),y_product_red_abs.shape[0])"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRihKwpcHSLs"
      },
      "source": [
        "### 7) Squared hinge (margin) loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZH0Gu5pdwQL"
      },
      "source": [
        "@tf.function\n",
        "def squared_hinge_loss(y_true, y_pred):\n",
        "  y_product = tf.math.multiply(y_true,y_pred)\n",
        "  max_second_arg = tf.constant(0.5) - y_product\n",
        "  max_compare = tf.math.maximum(tf.constant(0.0), max_second_arg) ** 2\n",
        "\n",
        "  y_product_red = tf.reduce_sum(max_compare,axis = 1, keepdims=True)\n",
        "  y_product_red_abs = tf.abs(y_product_red)\n",
        "\n",
        "  return tf.divide(tf.reduce_sum(y_product_red_abs),y_product_red_abs.shape[0])"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQeGyp0UHSzl"
      },
      "source": [
        "### 8) Cubed hinge (margin) loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCsSblN0eF8Z"
      },
      "source": [
        "@tf.function\n",
        "def cubed_hinge_loss(y_true, y_pred):\n",
        "  y_product = tf.math.multiply(y_true,y_pred)\n",
        "  max_second_arg = tf.constant(0.5) - y_product\n",
        "  max_compare = tf.math.maximum(tf.constant(0.0), max_second_arg) ** 3\n",
        "\n",
        "  y_product_red = tf.reduce_sum(max_compare,axis = 1, keepdims=True)\n",
        "  y_product_red_abs = tf.abs(y_product_red)\n",
        "\n",
        "  return tf.divide(tf.reduce_sum(y_product_red_abs),y_product_red_abs.shape[0])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMAnvK6P-Ure"
      },
      "source": [
        "### 9) Log (cross entropy) loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4pNIAtzeF7B"
      },
      "source": [
        "@tf.function\n",
        "def cross_entropy_loss(y_true, y_pred):\n",
        "  # Apply Softmax\n",
        "  y_pred_sum = tf.reduce_sum(y_pred,axis = 1, keepdims=True)\n",
        "  y_pred_ratio = tf.divide(y_pred,y_pred_sum)\n",
        "\n",
        "  # Apply Cross Entropy\n",
        "  #y_pred[sample][i] = tf.math.log(y_pred[sample][i])\n",
        "  y_log = tf.math.log(y_pred_ratio)\n",
        "  y_product = tf.math.multiply(y_true,y_log)\n",
        "  y_product_red = tf.reduce_sum(y_product,axis = 1, keepdims=True)\n",
        "  y_product_red_abs = tf.abs(y_product_red)\n",
        "\n",
        "  return tf.divide(tf.reduce_sum(y_product_red_abs),y_product_red_abs.shape[0])"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HP1Zdj2J-vaO"
      },
      "source": [
        "### 10) Squared log loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6Eofr1c--NM"
      },
      "source": [
        "@tf.function\n",
        "def squared_log_loss(y_true, y_pred):\n",
        "  # Apply Softmax\n",
        "  y_pred_sum = tf.reduce_sum(y_pred,axis = 1, keepdims=True)\n",
        "  y_pred_ratio = tf.divide(y_pred,y_pred_sum)\n",
        "\n",
        "  # Apply Cross Entropy\n",
        "  #y_pred[sample][i] = tf.math.log(y_pred[sample][i])\n",
        "  y_log = tf.math.log(y_pred_ratio)\n",
        "  y_square_product = tf.math.square(tf.math.multiply(y_true,y_log))\n",
        "  y_product_red = tf.reduce_sum(y_square_product,axis = 1, keepdims=True)\n",
        "  y_product_red_abs = tf.abs(y_product_red)\n",
        "\n",
        "  return tf.divide(tf.reduce_sum(y_product_red_abs),y_product_red_abs.shape[0])"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVvhgY-lIGQ4"
      },
      "source": [
        "### 11) Tanimoto loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-knSprLjKM4"
      },
      "source": [
        "@tf.function\n",
        "def tanimoto_loss(y_true, y_pred):\n",
        "  # Apply Softmax\n",
        "  y_pred_sum = tf.reduce_sum(y_pred,axis = 1, keepdims=True)\n",
        "  y_pred_ratio = tf.divide(y_pred,y_pred_sum)\n",
        "\n",
        "  # Apply Cross Entropy (Numerator Part)\n",
        "  y_product = tf.math.multiply(y_true,y_pred_ratio)\n",
        "  y_product_red = tf.reduce_sum(y_product,axis = 1, keepdims=True)\n",
        "  y_product_red_abs = tf.abs(y_product_red)\n",
        "\n",
        "  true_label_norm = tf.reshape(tf.norm(y_true, axis=1) ** 2, [y_pred.shape[0],1])\n",
        "  predicted_prob_norm = tf.reshape(tf.norm(y_pred_ratio, axis=1) ** 2, [y_pred.shape[0],1])\n",
        "  denominator_sum = predicted_prob_norm + true_label_norm - y_product_red_abs\n",
        "\n",
        "  tanimoto_loss_eq = tf.divide(y_product_red_abs,tf.abs(denominator_sum))\n",
        "\n",
        "  return tf.divide(tf.reduce_sum(tanimoto_loss_eq),tanimoto_loss_eq.shape[0])"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJFH263iIN9E"
      },
      "source": [
        "### 12) Cauchy-Schwarz Divergence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ad7A3LIBjKzj"
      },
      "source": [
        "@tf.function\n",
        "def cauchy_schwarz_divergence(y_true, y_pred):\n",
        "  # Apply Softmax\n",
        "  y_pred_sum = tf.reduce_sum(y_pred,axis = 1, keepdims=True)\n",
        "  y_pred_ratio = tf.divide(y_pred,y_pred_sum)\n",
        "\n",
        "  # Apply Cross Entropy (Numerator Part)\n",
        "  y_product = tf.math.multiply(y_true,y_pred_ratio)\n",
        "  y_product_red = tf.reduce_sum(y_product,axis = 1, keepdims=True)\n",
        "  y_product_red_abs = tf.abs(y_product_red)\n",
        "\n",
        "  true_label_norm = tf.reshape(tf.norm(y_true, axis=1), [y_pred.shape[0],1])\n",
        "  predicted_prob_norm = tf.reshape(tf.norm(y_pred_ratio, axis=1), [y_pred.shape[0],1])\n",
        "  denominator_product = tf.math.multiply(predicted_prob_norm, true_label_norm)\n",
        "\n",
        "  cauchy_schwarz_eq = tf.abs(tf.math.log(tf.divide(y_product_red_abs,denominator_product)))\n",
        "\n",
        "  return tf.divide(tf.reduce_sum(cauchy_schwarz_eq),cauchy_schwarz_eq.shape[0])"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1EwWO9m3bGg"
      },
      "source": [
        "## NN Sequential Models\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lv0Pvvuyzy59"
      },
      "source": [
        "def noise_app(y_train, percentage):\n",
        "  y_train_noisy = np.copy(y_train)\n",
        "  samples_size = int(percentage * len(y_train_noisy))\n",
        "  random_samples = np.random.choice(len(y_train_noisy), size=samples_size, replace=False)\n",
        "  b = y_train[random_samples]\n",
        "  np.random.shuffle(b)\n",
        "  y_train_noisy[random_samples] = b\n",
        "  return y_train_noisy"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RpFnjhTeHEa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d7af4f6-3225-490c-894e-8076d609de69"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten,\\\n",
        "                         Conv2D, MaxPooling2D, AveragePooling2D\n",
        "#from keras.layers.normalization import BatchNormalization\n",
        "from keras import regularizers\n",
        "#from keras.optimizers import Adam\n",
        "from keras.losses import categorical_crossentropy\n",
        "\n",
        "##########################################\n",
        "##########################################\n",
        "####### STUDY CONFIGURATIONS\n",
        "##########################################\n",
        "##########################################\n",
        "current_model = 'cifar10'\n",
        "apply_noise = True\n",
        "\n",
        "# Model Parameters\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.00003)\n",
        "num_of_classes = 10\n",
        "if current_model == 'cifar10':\n",
        "  #epochs = 100000\n",
        "  #batch_size = 100\n",
        "  epochs = 50\n",
        "  batch_size = 100\n",
        "  input_shape = input_shape_cifar10\n",
        "  Xtrain = Xtrain_cifar10\n",
        "  Ytrain = Ytrain_cifar10\n",
        "  Xtest = Xtest_cifar10\n",
        "  Ytest = Ytest_cifar10\n",
        "\n",
        "elif current_model == 'mnist':\n",
        "  #epochs = 100000\n",
        "  #batch_size = 100\n",
        "  epochs = 50\n",
        "  batch_size = 100\n",
        "  input_shape = input_shape_mnist\n",
        "  Xtrain = Xtrain_mnist\n",
        "  Ytrain = Ytrain_mnist\n",
        "  Xtest = Xtest_mnist\n",
        "  Ytest = Ytest_mnist\n",
        "\n",
        "print(\"Model Selected: \", current_model)\n",
        "print(\"epochs: \", epochs)\n",
        "print(\"batch_size: \", batch_size)\n",
        "print(\"input_shape: \", input_shape)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Selected:  cifar10\n",
            "epochs:  50\n",
            "batch_size:  100\n",
            "input_shape:  (32, 32, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8BD4yCbejjl"
      },
      "source": [
        "### MNIST Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ql9ALLlKJJyQ"
      },
      "source": [
        "def MNIST_Model(input_shape):\n",
        "  print('MNIST model')\n",
        "  num_classes = 10\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(Flatten(input_shape= input_shape))\n",
        "  model.add(Dense(512, activation='relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(512, activation='relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(512, activation='relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(512, activation='relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(512, activation='relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "\n",
        "  model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "  return model"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZg0LRFueoo7"
      },
      "source": [
        "### CIFAR10 Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JeNdWMyBNVUj"
      },
      "source": [
        "def CIFAR10_Model(input_shape):\n",
        "    \n",
        "    print('CIFAR 10 model')\n",
        "    num_classes = 10\n",
        "    model = Sequential()\n",
        "    \n",
        "    model.add(Conv2D(64, kernel_size=(5, 5), strides=(1, 1), activation='relu', input_shape=input_shape, padding='same'))\n",
        "    model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='valid'))\n",
        "    model.add(Conv2D(64, kernel_size=(5, 5), strides=(1, 1), activation='relu', padding='same'))\n",
        "    model.add(AveragePooling2D(pool_size=(3, 3), strides=(2, 2), padding='valid'))\n",
        "    model.add(Conv2D(64, kernel_size=(5, 5), strides=(1, 1), activation='relu', padding='same'))\n",
        "    model.add(AveragePooling2D(pool_size=(3, 3), strides=(2, 2), padding='valid'))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    return model"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OW5Zd53JezRS"
      },
      "source": [
        "### Loss Function Assignment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_0gOxmq_maO"
      },
      "source": [
        "loss_functions_array = [l1_loss, l2_loss, expectation_loss, regularized_expectation_loss, chebyshev_loss, \\\n",
        "                        hinge_loss, squared_hinge_loss, cubed_hinge_loss, cross_entropy_loss, squared_log_loss, \\\n",
        "                        tanimoto_loss, cauchy_schwarz_divergence]\n",
        "loss_functions_array_names = ['l1_loss', 'l2_loss', 'expectation_loss', 'regularized_expectation_loss', 'chebyshev_loss', \\\n",
        "                        'hinge_loss', 'squared_hinge_loss', 'cubed_hinge_loss', 'cross_entropy_loss', 'squared_log_loss', \\\n",
        "                        'tanimoto_loss', 'cauchy_schwarz_divergence']"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egL15iQztTDH"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKOdDvgf5YlZ"
      },
      "source": [
        "history_arr = []\n",
        "noise_arr = []\n",
        "noise_percentages = [0.1, 0.2, 0.4, 0.5]\n",
        "\n",
        "if apply_noise:\n",
        "  print(\"Noise Study is Applied\")\n",
        "  for noise_per in noise_percentages:\n",
        "    print(\"Noise Percentage: \", noise_per)\n",
        "    y_train_noisy = noise_app(Ytrain, noise_per)\n",
        "    for loss_fun_index, loss_fun in enumerate(loss_functions_array):\n",
        "      print(\"Loss Function Applied:\" , loss_functions_array_names[loss_fun_index])\n",
        "      if current_model == 'cifar10':\n",
        "        model = CIFAR10_Model(input_shape)\n",
        "      elif current_model == 'mnist':\n",
        "        model = MNIST_Model(input_shape)\n",
        "      model.compile(loss=loss_fun, optimizer=optimizer, metrics=['accuracy'])\n",
        "      history = model.fit(Xtrain, y_train_noisy, batch_size=batch_size, epochs=epochs, validation_data = (Xtest,Ytest))\n",
        "      history_arr.append(history)\n",
        "    noise_arr.append(history_arr)\n",
        "    history_arr = []\n",
        "else:\n",
        "  print(\"Noise Study is NOT Applied\")\n",
        "  for loss_fun_index, loss_fun in enumerate(loss_functions_array):\n",
        "    print(\"Loss Function Applied:\" , loss_functions_array_names[loss_fun_index])\n",
        "    if current_model == 'cifar10':\n",
        "      model = CIFAR10_Model(input_shape)\n",
        "    elif current_model == 'mnist':\n",
        "      model = MNIST_Model(input_shape)\n",
        "    model.compile(loss=loss_fun, optimizer=optimizer, metrics=['accuracy'])\n",
        "    history = model.fit(Xtrain, Ytrain, batch_size=batch_size, epochs=epochs, validation_data = (Xtest,Ytest))\n",
        "    history_arr.append(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6bNy-J9u-l6"
      },
      "source": [
        "##Plot results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGcvKLXpvjDu"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plot_width = 7\n",
        "plot_height = 6\n",
        "\n",
        "if apply_noise:\n",
        "  for noise_per_index in range(len(noise_percentages)):\n",
        "    \n",
        "    # summarize history for accuracy\n",
        "    plt.figure().set_figwidth(plot_width)\n",
        "    plt.figure().set_figheight(plot_height)\n",
        "    for history in noise_arr[noise_per_index]:\n",
        "      plt.plot(history.history['accuracy'])\n",
        "    if current_model == 'cifar10':\n",
        "      title_str = 'model accuracy CIFAR10 with noise: ' + str(noise_percentages[noise_per_index])\n",
        "      plt.title(title_str)\n",
        "    elif current_model == 'mnist':\n",
        "      title_str = 'model accuracy MNIST with noise: ' + str(noise_percentages[noise_per_index])\n",
        "      plt.title(title_str)\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylim(0.15, 0.4)\n",
        "    plt.legend(loss_functions_array_names, bbox_to_anchor=(1.6, 0), loc='lower right')\n",
        "    plt.show()\n",
        "\n",
        "    # summarize history for Test Accuracy\n",
        "    plt.figure().set_figwidth(plot_width)\n",
        "    plt.figure().set_figheight(plot_height)\n",
        "    for history in noise_arr[noise_per_index]:\n",
        "      plt.plot(history.history['val_accuracy'])\n",
        "    if current_model == 'cifar10':\n",
        "      title_str = 'model Test Accuracy CIFAR10 with noise: ' + str(noise_percentages[noise_per_index])\n",
        "      plt.title(title_str)\n",
        "    elif current_model == 'mnist':\n",
        "      title_str = 'model Test Accuracy MNIST with noise: ' + str(noise_percentages[noise_per_index])\n",
        "      plt.title(title_str)\n",
        "    plt.ylabel('Test Accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylim(0.25, 0.65)\n",
        "    plt.legend(loss_functions_array_names, bbox_to_anchor=(1.6, 0), loc='lower right')\n",
        "    plt.show()\n",
        "\n",
        "else:\n",
        "  # summarize history for accuracy\n",
        "  plt.figure().set_figwidth(plot_width)\n",
        "  plt.figure().set_figheight(plot_height)\n",
        "  for history in history_arr:\n",
        "    plt.plot(history.history['accuracy'])\n",
        "  if current_model == 'cifar10':\n",
        "    plt.title('model accuracy CIFAR10')\n",
        "  elif current_model == 'mnist':\n",
        "    plt.title('model accuracy MNIST')\n",
        "  plt.ylabel('accuracy')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.ylim(0.9, 1.0)\n",
        "  plt.legend(loss_functions_array_names, bbox_to_anchor=(1.6, 0), loc='lower right')\n",
        "  plt.show()\n",
        "\n",
        "  # summarize history for Test Accuracy\n",
        "  plt.figure().set_figwidth(plot_width)\n",
        "  plt.figure().set_figheight(plot_height)\n",
        "  for history in history_arr:\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "  if current_model == 'cifar10':\n",
        "    plt.title('model Test Accuracy CIFAR10')\n",
        "  elif current_model == 'mnist':\n",
        "    plt.title('model Test Accuracy MNIST')\n",
        "  plt.ylabel('Test Accuracy')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.ylim(0.9, 1.0)\n",
        "  plt.legend(loss_functions_array_names, bbox_to_anchor=(1.6, 0), loc='lower right')\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}